{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03: Spatial image processing\n",
    "\n",
    "The purpose of this lab is to practice preprocessing needed on T1 images images and spatial normalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "* import python tools for plotting 3D images\n",
    "* copy basic T1 and bold image from our osfshare for easy access to the files for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Copy files from lab 01 for easier work with them here\n",
    "# Name them generic names for ease of seeing how the command line programs work\n",
    "cp ../01-Lab/osfshare/sub-97-T1w_brain.nii.gz my_T1_brain.nii.gz\n",
    "cp ../01-Lab/osfshare/sub-97_task-flanker_bold.nii.gz my_bold.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did we get that \"brain\" image with the skull stripped  again?\n",
    "* FSL provides a tool called _bet_ which stands for _brain extraction tool_. See the [bet user manual here](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide). \n",
    "* It requires only the brain image with skull as input and has relatively few options. Performance is generally OK, but it is common to need to tweak the -f and -g options. \n",
    "* If you want to get serious about getting a great brain mask (e.g., your brains have many individual differences in shape due to atrophy), you should look to [ANTs](http://stnava.github.io/ANTs/). Here is an [example](https://dpaniukov.github.io/2016/06/06/brain-extraction-with-ants.html) of using their brain extraction tool\n",
    "* *Good brain extraction is essential to good registration*. If you see poor registration of your images later on then one place to start trouble-shooting is to look at the quality of your brain extraction by comparing the brain mask (what the program thinks is brain) to the image with the skull (did the program include non-brain tissues in the mask OR chop off part of the brain?)\n",
    "    - Never assume BET worked great, always check!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_bold.nii.gz\tmy_T1_brain.nii.gz  SpatialImageProcessing.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# refresher, are my images here?\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T1 image bias correction and image segmentation\n",
    "* FSL provides a nice tool called [FAST](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST) that combines bias field correction (see Handbook p56) and tissue segmentation\n",
    "* You will need to input a T1 image of the brain without skull, so brain extraction should be run before-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Part of FSL (build 509)\r\n",
      "FAST \r\n",
      "Copyright(c) 2004-2012, University of Oxford\r\n",
      "\r\n",
      "Usage: \r\n",
      "fast [options] file(s)\r\n",
      "\r\n",
      "Optional arguments (You may optionally specify one or more of):\r\n",
      "\t-n,--class\tnumber of tissue-type classes; default=3\r\n",
      "\t-I,--iter\tnumber of main-loop iterations during bias-field removal; default=4\r\n",
      "\t-l,--lowpass\tbias field smoothing extent (FWHM) in mm; default=20\r\n",
      "\t-t,--type\ttype of image 1=T1, 2=T2, 3=PD; default=T1\r\n",
      "\t-f,--fHard\tinitial segmentation spatial smoothness (during bias field estimation); default=0.02\r\n",
      "\t-g,--segments\toutputs a separate binary image for each tissue type\r\n",
      "\t-a <standard2input.mat> initialise using priors; you must supply a FLIRT transform\r\n",
      "\t-A <prior1> <prior2> <prior3>    alternative prior images\r\n",
      "\t--nopve\tturn off PVE (partial volume estimation)\r\n",
      "\t-b\t\toutput estimated bias field\r\n",
      "\t-B\t\toutput bias-corrected image\r\n",
      "\t-N,--nobias\tdo not remove bias field\r\n",
      "\t-S,--channels\tnumber of input images (channels); default 1\r\n",
      "\t-o,--out\toutput basename\r\n",
      "\t-P,--Prior\tuse priors throughout; you must also set the -a option\r\n",
      "\t-W,--init\tnumber of segmentation-initialisation iterations; default=15\r\n",
      "\t-R,--mixel\tspatial smoothness for mixeltype; default=0.3\r\n",
      "\t-O,--fixed\tnumber of main-loop iterations after bias-field removal; default=4\r\n",
      "\t-H,--Hyper\tsegmentation spatial smoothness; default=0.1\r\n",
      "\t-v,--verbose\tswitch on diagnostic messages\r\n",
      "\t-h,--help\tdisplay this message\r\n",
      "\t-s,--manualseg=<filename> Filename containing intensities\r\n",
      "\t-p\t\toutputs individual probability maps\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Look at usage\n",
    "!fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# example usage below\n",
    "# running this should take ~10 minutes\n",
    "fast -t 1 -n 3 -g -b -B -v -o my_T1_brain my_T1_brain.nii.gz > fast.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out what these options are doing\n",
    "# Verbose output can help with seeing under the hood and tracking the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast.log\t\t      my_T1_brain_pveseg.nii.gz\r\n",
      "my_bold.nii.gz\t\t      my_T1_brain_restore.nii.gz\r\n",
      "my_T1_brain_bias.nii.gz       my_T1_brain_seg_0.nii.gz\r\n",
      "my_T1_brain_mixeltype.nii.gz  my_T1_brain_seg_1.nii.gz\r\n",
      "my_T1_brain.nii.gz\t      my_T1_brain_seg_2.nii.gz\r\n",
      "my_T1_brain_pve_0.nii.gz      my_T1_brain_seg.nii.gz\r\n",
      "my_T1_brain_pve_1.nii.gz      SpatialImageProcessing.ipynb\r\n",
      "my_T1_brain_pve_2.nii.gz\r\n"
     ]
    }
   ],
   "source": [
    "# Check outputs\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: \n",
    "* Use FSLview to open your T1 image with the \"seg\" images overlayed on top\n",
    "* What do these images represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fslview my_T1_brain.nii.gz my_T1_brain_seg_0.nii.gz my_T1_brain_seg_1.nii.gz my_T1_brain_seg_2.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The bias corrected image ends with \"restore\" - take a look and compare values in the view and by looking at their histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial registration\n",
    "* Now let's walk through how to spatially align our high-resolution T1 image and our functional bold image to the MNI-152 standard template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open MNI 152 template in FSLview\n",
    "* Open standard > MNI152_T1_2mm_brain\n",
    "* Where is origin?\n",
    "* What does 2mm refer to in the file name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fslview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
