{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: SoftwareIntro\n",
    "The purpose of this homework is to guide you through opening the programs you've downloaded through Neurodebian and getting familiar with some of their basic functions to understand the basics of how images are stored and how we can interact with them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download example data\n",
    "\n",
    "We will first download some practice MRI data from open science framework. While this is not a common outlet for scientists to share their MR imaging datasets, this is a useful repository for files that are larger than we would want to put on github and are in a simplified storage format for teaching and demonstrations like this one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#the following bash commands will allow us to download the data using command line tools\n",
    "#this may take a little time, it is done when the astericks goes away\n",
    "wget -O lab01_images.tar.gz https://osf.io/bprq5/download/\n",
    "tar -xvf lab01_images.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd; ls  #tell me present working directoy; then list contents of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls ./osfshare  #list contents within osfshare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the data directly in jupyter\n",
    "\n",
    "We'll first get used to terms about the spatial orientation of an MR image. We'll use a viewer that is part of nipy, which is a collection of neuroimaging tools written in the python programming language. \n",
    "\n",
    "More information about the NiftiWidget can be found here: http://nipy.org/niwidgets/examples.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import an example image that comes with the package__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import the widget from the niwidgets package\n",
    "from niwidgets import NiftiWidget   \n",
    "\n",
    "#import example data that comes with niwidgets\n",
    "from niwidgets import examplet1   \n",
    "\n",
    "#commands that open the image in the widget\n",
    "test_widget = NiftiWidget(examplet1)\n",
    "test_widget.nifti_plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import our own image__ <br>\n",
    "What are some similarities and differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give our anatomical image a variable name\n",
    "mydata='./osfshare/sub-97-T1w_defaced.nii.gz'\n",
    "\n",
    "#what exactly does each do below\n",
    "mydata_widget = NiftiWidget(mydata)\n",
    "mydata_widget.nifti_plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images we have been viewing are high-resolution images using [T1 contrast](http://www.med.harvard.edu/aanlib/basicsMR.html), and the image format is [nifti](https://brainder.org/2012/09/23/the-nifti-file-format/). As you see above, the image is 3-dimensional and can be opened in 3 orthogonal views simultaneously; coronal, sagittal and axial views.The viewer above is useful for getting familiar with the x,y,and z \"planes\" of the image. Every 3-dimensional pixel in the image (called a voxel) has a unique x,y,z coordinate.  <br>\n",
    "<br>\n",
    "It is also common to refer to different parts of the image by their location in neuroanatomical terms: L, R, A, P, S, I (Left, Right, Anterior=front, Posterior=back, Superior=top, Inferior=bottom). We will see that some viewers will show us these labels and \"Left\" in the image is not always the \"Left\" part of the head! <br>\n",
    "<br>\n",
    "It may be obvious, but also note that in these images we cannot see at the level of single neurons. The anatomy we focus on with MRI is from a \"macroscopic\" view. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSL package viewer\n",
    "\n",
    "A very common neuroimaging package is FSL. FSL has viewer that we can open in the bash terminal, and it has some very helpful features for understanding more about images.\n",
    "\n",
    "__We'll first see how to:__ <br>\n",
    "<br>\n",
    "__(a) learn basic information about the image attributes__ <br> \n",
    "-What kind of image is this <br>\n",
    "-What is the voxel size <br>\n",
    "-Others? <br>\n",
    "<br>\n",
    "__(b) look at the image histogram.__ <br>\n",
    "An image histogram shows the distribution of all the intensity values that make up the image. Looking at these is helpful to see what intensities are generally “brain” versus background and to get comfortable with the idea that images are a collection of voxels with different intensity values (e.g., see Handbook Figure 2.1, p14). The intensity values mean something about what tissue we *think* we’re seeing based on the physics of MRI. It is also helpful to remember that the basis of most image processing tools is signal processing and statistics on these intensity values to improve the detection of the \"signal\" we're interested in (e.g., brain structure or activity) relative to noise (e.g., motion). <br>\n",
    "-What is the range of values in our sub-97-T1w_defaced.nii.gz image <br>\n",
    "-Is the histogram multi-modal? What would that tell us?  <br>\n",
    "-What are the typical values for gray matter, white matter, and CSF? <br>\n",
    "<br>\n",
    "__(c) look at our functional image and its timeseries.__ <br>\n",
    "-Compare and contrast the image intensities of white matter and gray matter from the structural with the functional image. <br>\n",
    "-Show the image timeseries <br>\n",
    "-Show the movie of volumes over time, how many dimensions is the file? <br>\n",
    "-Compare the spatial resolution of the structural and functional <br>\n",
    "-Can we overlay the functional on top of the structural image? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#the viewer version we'll use is called fslview\n",
    "#open in the command line by typing fslview and hitting enter\n",
    "fslview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image meta-data\n",
    "\n",
    "In addition to the information in the image, another important aspect of data with the images is their meta-data (Handbook, p14). This information is often stored in a [header](http://nipy.org/nibabel/nibabel_images.html#the-image-header) that is tagged onto the image file itself or as a separate file. For nifti images the header information is kept tagged onto the image itself, so it is a handy to know how to look at the header for images on the command line. We'll see how to do this with fsl and nibabel below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import os\n",
    "\n",
    "#below is a different way to assign variable names to directories and files\n",
    "datadir=\"./osfshare/\"\n",
    "anat_file=os.path.join(datadir,\"sub-97-T1w_brain.nii.gz\")\n",
    "anat_file\n",
    "anat_image=nb.load(anat_file)\n",
    "func_file=os.path.join(datadir,\"sub-97_task-flanker_bold.nii.gz\")\n",
    "func_file\n",
    "func_image=nb.load(func_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at metadata for dimensions of our image, compare to what we saw with fslview\n",
    "anat_image.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header\n",
    "anat_image.header  #this is the header object\n",
    "print(anat_image.header)  #print it to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#fsl also makes it easy to see header information on the command line with fslhd\n",
    "fslhd ./osfshare/sub-97-T1w_brain.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate systems and affines\n",
    "\n",
    "As described in the Handbook (Ch 2), images are arrays of numbers. We also need to consider how that image is positioned in space, and we'll get a more hands-on look at this information here. Many of these examples are used from this excellent reference on [arrays](http://nipy.org/nibabel/coordinate_systems.html). In particular, be sure we discuss the [naming of reference spaces](http://nipy.org/nibabel/coordinate_systems.html#naming-reference-spaces) in relation to what we see below, and we'll need to understand the qform and sform information in the headers as described more [here](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Orientation%20Explained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot the image with the voxel coordinate system viewable\n",
    "import pylab as plt\n",
    "\n",
    "#the get_data() function allows us to access the actual data in the image object. This will load the image data into memory. \n",
    "data=anat_image.get_data()\n",
    "\n",
    "#try these different commands, what is happening here?\n",
    "\n",
    "plt.imshow(data[:,:,89],cmap=\"gray\")\n",
    "#plt.imshow(data[160,:,:],cmap=\"gray\")\n",
    "#plt.imshow(data[:,104,:],cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#now let's use fslview to visually compare coordinates for the image in voxel space (voxels) and scanner space (mm) \n",
    "#do you remember how to open fslview from the command line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at using matrices to represent the spatial transformations between different image \"spaces.\" Review this [explanation](http://nipy.org/nibabel/coordinate_systems.html#the-affine-matrix-as-a-transformation-between-spaces) which complements and extends the information in the Handbook Box 2.3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at affine array for our anatomical image\n",
    "#this  maps the voxel coordinates to scanner coordinates\n",
    "anat_image.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#let's change the orientation of the image and see how it affects the affine matrix\n",
    "#the following fsl program allows you to change the orientation of your image\n",
    "#you can type the name of the program into the bash terminal to see the usage:\n",
    "fslswapdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#let's swap the dimension of our image across the y axis and see what happens\n",
    "fslswapdim ./osfshare/sub-97-T1w_brain.nii.gz -x y z ./osfshare/sub-97-T1w_brain_LPI.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##is the change reflected in the header?  how can you check?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#compare images by loading them all together\n",
    "fslview ./osfshare/sub-97-T1w_brain_LPI.nii.gz ./osfshare/sub-97-T1w_brain.nii.gz ./osfshare/sub-97-T1w_defaced.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#a useful tool..\n",
    "fslorient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fslorient -swaporient ./osfshare/sub-97-T1w_brain_LPI.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "#now look, what changed?\n",
    "fslhd ./osfshare/sub-97-T1w_brain_LPI.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fslview ./osfshare/sub-97-T1w_brain_LPI.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## Practice problems \n",
    "\n",
    "Below we list some practice problems to review what we've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1)_ Extract the dimensions of the functional image using nipype commands as we did for the anatomical above. Show your work below. Then in the markdown cell explain what the dimensions are and what they mean in words. (e.g., \"The dimensions of each volume are --- and the were --- volumes in the timeseries\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer in words here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2)_ Compare the image intensity values for the structural and functional image for the same brain tissue types. What tissues are brightest in the T1-weighted structural image? How does this compare to the intensities in the T2-weighted functional image. Use a code cell below to give an example from a given coordinate, and explain your answer in words in the following markdown cell. It may also help to refer to Ch2 in our Handbook text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer in words here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3)_ Use what we learned about affine representations for images to explain: <br>\n",
    "<br>\n",
    "_a)_ Why is there a *-1* in the the [1,1] affine matrix element for our T1-weighted image and how does it change when we reorient the image? It may help to re-read [this page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Orientation%20Explained). These operations are used often and can be buried in early data reconstruction scripts so you want to understand and know how to check this information!<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer in words here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_b)_ What do the values in column 4 of the affine matrix refer to. Include what kind of transformation this is on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer in words here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
