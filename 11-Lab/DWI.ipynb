{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Weighted Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will be treading some old grounds with a new perspective. \n",
    "Functional (fMRI) and diffusion (dMRI) data require similar processing such as motion correction, denoising, masking, and modelling. \n",
    "We will complete this lab using only python commands, which means we will see familiar FSL commands in a new light.\n",
    "\n",
    "**Learning Objectives**\n",
    "- Learn the steps to process diffusion weighted data\n",
    "- Be aware of some common gotchas! (e.g. rotating B vectors and data representations)\n",
    "- Learn Nipype basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# lab prep\n",
    "# need access to ants utilities\n",
    "path='export PATH=\"/usr/lib/ants:$PATH\"'\n",
    "proper_path=$(grep \"${path}\" ~/.bashrc)\n",
    "if [[ ${proper_path} == \"\" ]]; then\n",
    "    echo ${path} >> ~/.bashrc\n",
    "fi\n",
    "\n",
    "# need another python module\n",
    "pip install scikit-image\n",
    "\n",
    "# install dipy\n",
    "conda install dipy vtk -c conda-forge\n",
    "\n",
    "if [ ! -d 'derivatives' ]; then\n",
    "    wget --quiet -O 11-Lab_data.tar.gz https://osf.io/hde8t/download &&\\\n",
    "    tar -xf 11-Lab_data.tar.gz &&\\\n",
    "    rm 11-Lab_data.tar.gz\n",
    "fi\n",
    "\n",
    "\n",
    "# exit the notebook, and type source ~/.bashrc in the terminal and open the notebook again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook prep\n",
    "%matplotlib inline\n",
    "# modules to preprocess the data\n",
    "from nipype.workflows.dmri.fsl.artifacts import hmc_pipeline\n",
    "from dwi_preprocess import ecc_pipeline\n",
    "from nipype.workflows.dmri.fsl.utils import rotate_bvecs\n",
    "\n",
    "# nipype utilities for building workflows\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "from nipype.interfaces import utility as niu\n",
    "\n",
    "# for various file operations\n",
    "import os\n",
    "\n",
    "# making a mask\n",
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "# for loading nifti files into python\n",
    "import nibabel as nib\n",
    "\n",
    "# for applying mathematical oeprations to nifti objects\n",
    "import numpy as np\n",
    "\n",
    "# visualizing results\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Masking\n",
    "We have seen masking using [bet](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide), but sometimes a simpler method suffices. The [median otsu](https://en.wikipedia.org/wiki/Otsu%27s_method) is another image processing algorithm that's found use in the world of MRI.We will be using [dipy's implementation of this algorithm](http://nipy.org/dipy/reference/dipy.segment.html#dipy.segment.mask.median_otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input file\n",
    "dwi_nii = './sub-999/ses-activepre/dwi/sub-999_ses-activepre_dwi.nii.gz'\n",
    "\n",
    "# load the file into python\n",
    "dwi_img = nib.load(dwi_nii)\n",
    "\n",
    "# access the 4D data matrix in the python object\n",
    "dwi_data = dwi_img.get_data()\n",
    "\n",
    "# mask the data\n",
    "_, mask_data = median_otsu(dwi_data)\n",
    "\n",
    "# make the mask a python image object\n",
    "mask_img = nib.Nifti1Image(mask_data.astype(np.float32), dwi_img.affine)\n",
    "\n",
    "# set the output directory\n",
    "fout = os.path.join(os.getcwd(), \n",
    "                    'derivatives/otsu_mask/sub-999/ses-activepre/dwi')\n",
    "\n",
    "# make the output directory\n",
    "os.makedirs(fout, exist_ok=True)\n",
    "\n",
    "# set the output name of the file\n",
    "fname = 'sub-999_ses-activepre_dwi_mask.nii.gz'\n",
    "out_fname = os.path.join(fout, fname)\n",
    "\n",
    "# save the output as a nifti file\n",
    "fmask = nib.save(mask_img, out_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the mask\n",
    "# grab the first volume of the dwi (a B0)\n",
    "first_vol_data = dwi_data[:,:,:,0]\n",
    "# make the volume a python nifti object\n",
    "first_vol_img = nib.Nifti1Image(first_vol_data.astype(np.float32), dwi_img.affine)\n",
    "# plot the mask\n",
    "plotting.plot_roi(roi_img=out_fname, bg_img=first_vol_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Head Motion/Eddy Current Correction\n",
    "Just as people move during resting state or task fmri, they will also move when we collect diffusion weighted imaging. In addition, due to [eddy currents](http://mriquestions.com/eddy-current-problems.html), there are shears in the data unique to each magnetic vector (direction) applied. In our example  scan, we have 64 unique directions, and therefor the data are sheared in 64 unique ways. To convince ourselves of this, let's take a look at some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for vol_idx in range(10, 60, 10):\n",
    "    tmp_img = nib.Nifti1Image(dwi_data[:,:,:,vol_idx], dwi_img.affine)\n",
    "    plotting.plot_anat(tmp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are going to setup a \"[workflow](https://miykael.github.io/nipype_tutorial/notebooks/basic_workflow.html)\" using [nipype](http://nipype.readthedocs.io/en/latest/). A workflow is a set of processing steps we would like to run together. For example, FEAT completes multiple steps for slice-timing correction, motion correction, spatial smoothing, temporal filtering, etc. Nipype gives us the ability to contruct these workflows all within python.\n",
    "\n",
    "### DO NOT RUN THE CODE IN THE BELOW BLOCK (I've ran it for you...it takes 30-45 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a working directory for intermediate outputs\n",
    "os.makedirs('work', exist_ok=True)\n",
    "# set a variable to that working directory\n",
    "work_dir = os.path.join(os.getcwd(), 'work')\n",
    "\n",
    "# set the templates for the files we want to match\n",
    "templates = dict(dwi_nii=\"sub-{sub_label}/ses-{ses_label}/dwi/sub-{sub_label}_ses-{ses_label}_dwi.nii.gz\",\n",
    "                 bvals=\"sub-{sub_label}/ses-{ses_label}/dwi/sub-{sub_label}_ses-{ses_label}_dwi.bval\",\n",
    "                 bvecs=\"sub-{sub_label}/ses-{ses_label}/dwi/sub-{sub_label}_ses-{ses_label}_dwi.bvec\",\n",
    "                 mask=\"derivatives/otsu_mask/sub-{sub_label}/ses-{ses_label}/dwi/sub-{sub_label}_ses-{ses_label}_dwi_mask.nii.gz\")\n",
    "\n",
    "# make the node to match the templates\n",
    "inputnode = pe.Node(nio.SelectFiles(templates), name='inputnode')\n",
    "\n",
    "# set the node inputs to the desired inputs\n",
    "inputnode.inputs.base_directory = os.getcwd()\n",
    "inputnode.inputs.sub_label = '999'\n",
    "inputnode.inputs.ses_label = 'activepre'\n",
    "\n",
    "\n",
    "# head motion correction workflow\n",
    "hmc_wf = hmc_pipeline(name='hmc_wf')\n",
    "\n",
    "# eddy current correction workflow\n",
    "ecc_wf = ecc_pipeline(name='ecc_wf')\n",
    "\n",
    "# rotate the transformed b vectors\n",
    "rotate_bvec = pe.Node(\n",
    "    niu.Function(\n",
    "        input_names=['in_bvec', 'in_matrix'],\n",
    "        output_names=['out_file'],\n",
    "        function=rotate_bvecs),\n",
    "        name='rotate_bvec')\n",
    "\n",
    "# collect the outputs\n",
    "ds_output = pe.Node(nio.DataSink(), name='ds_output')\n",
    "ds_output.inputs.base_directory = os.path.join(os.getcwd(), 'derivatives/preproc/sub-999/ses-activepre/dwi/')\n",
    "\n",
    "# the workflow\n",
    "dwi_preproc = pe.Workflow(name='dwi_preproc')\n",
    "\n",
    "dwi_preproc.connect([\n",
    "    (inputnode, hmc_wf, [('dwi_nii', 'inputnode.in_file'),\n",
    "                         ('mask', 'inputnode.in_mask'),\n",
    "                         ('bvals', 'inputnode.in_bval'),\n",
    "                         ('bvecs', 'inputnode.in_bvec')]),\n",
    "    (inputnode, ecc_wf, [('bvals', 'inputnode.in_bval'),\n",
    "                         ('dwi_nii', 'inputnode.in_file'),\n",
    "                         ('mask', 'inputnode.in_mask')]),\n",
    "    (hmc_wf, ecc_wf, [('outputnode.out_xfms', 'inputnode.in_xfms')]),\n",
    "    (ecc_wf, rotate_bvec, [('outputnode.out_xfms', 'in_matrix')]),\n",
    "    (inputnode, rotate_bvec, [('bvecs', 'in_bvec')]),\n",
    "    (rotate_bvec, ds_output, [('out_file', 'bvec')]),\n",
    "    (ecc_wf, ds_output, [('outputnode.out_file', 'dwi_eddy_corr')]),\n",
    "])\n",
    "\n",
    "# place all the intermediate results in the work directory\n",
    "dwi_preproc.base_dir = work_dir\n",
    "# run the workflow\n",
    "dwi_preproc.run()\n",
    "# make an illustration of the workflow\n",
    "dwi_preproc.write_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![workflow](work/dwi_preproc/graph.png \"so workflowy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Read in the processed diffusion data and denoise with local PCA\n",
    "Now that we've motion/eddy corrected the image, we will do some additional denoising of the data to boost our signal to noise ratio using [dipy](http://nipy.org/dipy/). Specifically we will be using [local PCA](http://nipy.org/dipy/examples_built/denoise_localpca.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.reconst.dti import fractional_anisotropy\n",
    "import dipy.reconst.dti as dti\n",
    "import numpy as np\n",
    "from dipy.denoise.localpca import localpca\n",
    "from dipy.denoise.pca_noise_estimate import pca_noise_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdwi_preproc = os.path.join(os.getcwd(), 'derivatives/preproc/sub-999/ses-activepre/dwi/dwi_eddy_corr/sub-999_ses-activepre_dwi_eccorrect.nii.gz')\n",
    "fbval = os.path.join(os.getcwd(), './sub-999/ses-activepre/dwi/sub-999_ses-activepre_dwi.bval')\n",
    "fbvec_preproc = os.path.join(os.getcwd(), 'derivatives/preproc/sub-999/ses-activepre/dwi/bvec/sub-999_ses-activepre_dwi_rotated.bvec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the diffusion image as a python object\n",
    "img_preproc = nib.load(fdwi_preproc)\n",
    "\n",
    "# access the array of the python object\n",
    "data_preproc = img_preproc.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the preprocessed data (becomes a 2D array)\n",
    "mask_preproc_data = data_preproc[mask_data]\n",
    "\n",
    "# create the correctly shaped array (128, 128, 70, 74)\n",
    "data_preproc_masked = np.zeros(data_preproc.shape, dtype=data_preproc.dtype)\n",
    "\n",
    "# fill in the 4D array of zeros with data from the 2D array\n",
    "data_preproc_masked[mask_data] = mask_preproc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the bvals and bvecs into python\n",
    "bvals, bvecs_preproc = read_bvals_bvecs(fbval, fbvec_preproc)\n",
    "gtab_preproc = gradient_table(bvals, bvecs_preproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the sigma to use for denoising\n",
    "sigma = pca_noise_estimate(data_preproc_masked, gtab_preproc, correct_bias=True, smooth=3)\n",
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise data with localpca\n",
    "data_denoised = localpca(data_preproc_masked, sigma=sigma, patch_radius=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit a tensor model on our preprocessed diffusion weighted data\n",
    "We can now fit a tensor model using [dipy](http://nipy.org/dipy/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the tensor model with the vectors and fit it to our data\n",
    "tenmodel_preproc = dti.TensorModel(gtab_preproc)\n",
    "tenfit_preproc = tenmodel_preproc.fit(data_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Fractional Anisotropy\n",
    "Remember fraction anisotropy is measured using the dominant gradient direction in the numerator and the two orthogonal gradients in the demoninator.\n",
    "$$FA = \\sqrt{3/2} * \\frac{\\sqrt{(\\lambda_1 - \\hat{\\lambda})^2 + (\\lambda_2 - \\hat{\\lambda})^2 + (\\lambda_3 - \\hat{\\lambda})^2}} {\\sqrt{\\lambda_1^2 + \\lambda_2^2 + \\lambda_3^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractional anisotropy\n",
    "fa_preproc = fractional_anisotropy(tenfit_preproc.evals)\n",
    "# zero any elements that are NaN (Not a Number)\n",
    "fa_preproc[np.isnan(fa_preproc)] = 0\n",
    "# Save the fa_output as an image\n",
    "fa_img = nib.Nifti1Image(fa_preproc.astype(np.float32), img_preproc.affine)\n",
    "nib.save(fa_img, 'fa_preproc.nii.gz')\n",
    "fa_file = os.path.join(os.getcwd(), 'fa_preproc.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Measure FA of the Forceps Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSL's FA template\n",
    "template = '/usr/share/fsl/data/standard/FMRIB58_FA_1mm.nii.gz'\n",
    "\n",
    "# setup flirt sub2mni\n",
    "flirt = fsl.FLIRT(in_file=fa_file, \n",
    "                  reference=template, \n",
    "                  out_matrix_file='dwi2mni.mat')\n",
    "\n",
    "# display the commandline\n",
    "display(flirt.cmdline)\n",
    "\n",
    "# run the function\n",
    "flirt_res = flirt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup fnirt sub2mni\n",
    "fnirt = fsl.FNIRT(in_file=fa_file, \n",
    "                  affine_file=flirt_res.outputs.out_matrix_file,\n",
    "                  ref_file=template,\n",
    "                  config_file='FA_2_FMRIB58_1mm',\n",
    "                  field_file='dwi2mni_warp')\n",
    "\n",
    "# display the commandline\n",
    "display(fnirt.cmdline)\n",
    "\n",
    "# run the function\n",
    "fnirt_res = fnirt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the inverse of the warp generated by fnirt\n",
    "invwarp = fsl.InvWarp(warp='dwi2mni_warp.nii.gz',\n",
    "                      reference=fa_file,\n",
    "                      inverse_warp='mni2dwi_warp.nii.gz')\n",
    "\n",
    "display(invwarp.cmdline)\n",
    "invwarp_res = invwarp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source file for tracts /usr/share/fsl/data/atlases/JHU-tracts.xml\n",
    "\n",
    "# this file contains the tracts listed in the above xml file\n",
    "tract_atlas = '/usr/share/fsl/data/atlases/JHU/JHU-ICBM-tracts-maxprob-thr25-2mm.nii.gz'\n",
    "\n",
    "# Select the forceps major from the atlas\n",
    "forceps_major = fsl.Threshold(in_file=tract_atlas,\n",
    "                              thresh=8,\n",
    "                              args='-uthr 8 -bin',\n",
    "                              out_file='forceps_major.nii.gz')\n",
    "\n",
    "display(forceps_major.cmdline)\n",
    "forceps_major_res = forceps_major.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(forceps_major_res.outputs.out_file, bg_img=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the mni2dwi_warp to the forceps_major\n",
    "forceps_major_sub = fsl.ApplyWarp(in_file=forceps_major_res.outputs.out_file, \n",
    "                                  ref_file=fa_file,\n",
    "                                  interp='nn',\n",
    "                                  field_file=invwarp_res.outputs.inverse_warp,\n",
    "                                  out_file='sub-999_forceps_major.nii.gz')\n",
    "\n",
    "display(forceps_major_sub.cmdline)\n",
    "forceps_major_sub_res = forceps_major_sub.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(forceps_major_sub_res.outputs.out_file, bg_img=fa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the average FA from the Forceps Major\n",
    "forceps_major_fa = fsl.ImageStats(in_file=fa_file, \n",
    "                                  mask_file=forceps_major_sub_res.outputs.out_file,\n",
    "                                  op_string='-M')\n",
    "\n",
    "display(forceps_major_fa.cmdline)\n",
    "forceps_major_fa_res = forceps_major_fa.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the result\n",
    "forceps_major_fa_res.outputs.out_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Let's see how preprocessing has impacted our results. Instead of doing all the preprocessing, let's use the raw unprocessed data instead. \n",
    "        - the raw dwi file is here: ./sub-999/ses-activepre/dwi/sub-999_ses-activepre_dwi.nii.gz\n",
    "        - the raw bvec file is here: ./sub-999/ses-activepre/dwi/sub-999_ses-activepre_dwi.bvec\n",
    "The output will be the average FA of the Forceps Major (processed forceps_major_FA_ave = 0.243983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Choose another tract you are interested in and calculate the average FA of that region.\n",
    "\n",
    "Outputs:\n",
    "- Plot the region you chose in both MNI and subject space like we did in lab.\n",
    "- The FA statistic from the region you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
