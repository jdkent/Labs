{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07: Building a task model for a single subject\n",
    "\n",
    "\n",
    "The purpose of this lab is to walk through steps for building a statistical model for task-evoked changes in BOLD signal. Up to now we have practiced steps involved in preprocessing via the command-line. In today's lab we'll see how to set up these steps with the GUI in FSL, and then test for task-related activation. \n",
    "\n",
    "We will use our sub-97 test data, and get a feel for how different analysis decisions affect our result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Steps fix the python version of one of FSL's scripts\n",
    "\n",
    "# # step 1\n",
    "# cd /usr/share/fsl/5.0/bin\n",
    "\n",
    "# # step 2\n",
    "# sudo chmod 777 imglob\n",
    "\n",
    "# # step 3\n",
    "# atom imglob\n",
    "\n",
    "# # step 4 \n",
    "# # on the first line change #!/usr/bin/env python to #!/usr/bin/env python2\n",
    "\n",
    "# # step 5\n",
    "# # save!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download fresh data and task \"evs\" (explanatory variables)\n",
    "wget --quiet -O 07-Lab_data.tar.gz https://osf.io/v9hcq/download &&\\\n",
    "tar -xf 07-Lab_data.tar.gz &&\\\n",
    "rm 07-Lab_data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cognitive task: flanker\n",
    "\n",
    "![fig](img/task.png)\n",
    "\n",
    "* Three trial types\n",
    "    * _Congruent_: all arrows going in the same direction (>>>>>)\n",
    "    * _Incongruent_: the flanking arrows are going in the opposite direction (>><>>)\n",
    "    * _Neutral_: the flankers have no intrinsic direction (-->--)\n",
    "    * _Contrast of interest_: what regions are involved in resolving the response conflict elicited by the incongruent condition compared to the congruent and neutral conditions?\n",
    "* Trial information\n",
    "    * Inter-trial interval was 2.72 seconds with \"null\" fixation events to add jitter\n",
    "    * 40 trials of each condition (120 total) with 40 \"null\" trials of fixation only in an order determined by optseq\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open example design file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will open the design file using the FSL GUI\n",
    "fsl &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example design would run a first-level analysis with:\n",
    "* Data\n",
    "    * Input: reconstructed bold image\n",
    "    * Output location: /home/brain/uiowa-mri-course-2018/labs-[your github name]/filtered (fsl will automatically add .feat)\n",
    "    * High-pass: 100s\n",
    "* Pre-stats\n",
    "    * Motion correction reference: default as middle volume\n",
    "    * Motion correction: Yes\n",
    "    * Slice timing: No\n",
    "    * BET on functional image: Yes\n",
    "    * Spatial smoothing: 6mm FWHM\n",
    "* Registration\n",
    "    * 6DOF for EPI to T1, and 12 DOF for T1 to MNI (quicker thank non-linear for class demo)\n",
    "* Stats\n",
    "    * Prewhitening: Yes (always when doing task analyses!)\n",
    "    * Regressors: task conditions, error trials, their temporal derivatives\n",
    "\n",
    "To run the basic analysis hit **Go**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a first-level design in FSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we call this \"first-level\"?\n",
    "* Notes\n",
    "\n",
    "What is FSL's tool for running the general linear model with timeseries data?\n",
    "* Notes\n",
    "\n",
    "What is the parameter file that specifies your preprocessing and/or first-level design after set up with FSL?\n",
    "* Notes\n",
    "\n",
    "What is the format of our task schedule file?\n",
    "* Notes\n",
    "\n",
    "What is the difference between Real and Original EVs?\n",
    "* Notes\n",
    "\n",
    "How is the F-test different than each contrast?\n",
    "* Notes\n",
    "\n",
    "What is pre-threshold masking?\n",
    "* Notes\n",
    "\n",
    "Workflow overview\n",
    "* set up analysis and task design in the FSL GUI with a pilot subject (practice today)\n",
    "* inspect results (practice today)\n",
    "* use optimal design file as a template and fill in information unique to each subject and run (practice later)\n",
    "    * run in a script with new subjects by using programming to search and replace values that change per subject\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and modifying design files\n",
    "\n",
    "* Find the design file you just ran within the filtered.feat output\n",
    "* Modify the design to include 6 motion regressors and our motion outliers timing file\n",
    "* Add an F-test that you might be interested in examining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the output [FSL DOCS](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT/UserGuide#FEAT_Output)\n",
    "\n",
    "* Preprocessing outputs\n",
    "    * example_func\n",
    "    * filtered_func_data\n",
    "    * mc directory\n",
    "    * reg directory\n",
    "* Analysis outputs\n",
    "    * stats directory\n",
    "        * copes\n",
    "        * pe\n",
    "        * res4d\n",
    "        * sigmasquareds\n",
    "        * threshac1 - related to estimates of auto-correlation in the residuals during pre-whitening with FILM\n",
    "        * varcopes\n",
    "        * tstats and zstats\n",
    "        * what space are these images in?\n",
    "    * Thresholded stats images\n",
    "        * thresh_ images\n",
    "        * rendered_thresh\n",
    "        * cluster_zstat\n",
    "    * View a summary of the output in the report.html page\n",
    "        * /home/brain/uiowa-mri-course-2018/labs-[your github name]/filtered.feat/report.html\n",
    "        * Activation maps and coordinates\n",
    "        * Timeseries plots\n",
    "            * full model fit: shows what happens when all EVs are used in the fit\n",
    "            * cope partial model fit: shows what happens when only the EVs from the contrast are used \n",
    "    * Open example func and overlay zstat1 in fslview\n",
    "        * find the peak for activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of including the activation .png files in your notebook\n",
    "\n",
    "The activation for con>0 in the basic design\n",
    "![fig](filtered.feat/rendered_thresh_zstat1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1)_ Determine if using task regressors that account for trial-by-trial reaction time (RT) changes the results (e.g. use RTdur instead of fixdur for the EV file inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what you changed and show a figure to highlight similarities and/or differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2)_ Use the manual for ICA-AROMA (located your ICA-AROMA directory named `Manual.pdf`) to run your fixed trial duration design following clean-up with ICA-AROMA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_a)_ First run a design where you only run preprocessing without high-pass filtering. ICA-AROMA would also like to see non-linear registration. TIP: to run just the preprocessing without the task statistics, click on the button on the top right that says \"Full analysis\" and select \"Preprocessing\" instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_b)_ Next use the cleaned functional image from ICA-AROMA as your input 4D and set up your task design as we did in class (except set `Spatial smoothing FWHM (mm)` to zero since our ICA-AROMA 4d image is already spatially smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe whether you think ICA-AROMA helped clean up the results and show figures to highlight similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3)_ Based on your observations, what do you think would be the optimal single-subject analysis settings for this task and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your notes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
